# 宗旨

本文旨在完成生产可用的k8s集群的网络规划并主要侧重流量切分，使得管理所需的流量与租户容器的流量以及访问存储和中间件的流量不会混杂在一起

# 前提与假设

* 当前规划是在1个可用域(region)内，跨可用域默认情况下应当认为会单独部署1套集群，而不是将本地集群的网络扩展到新的可用域
* 规划按照1个可用域有3个可用区(Availability Zone)执行

# 管理网络

管理网络是k8s集群以及相关辅助设施和服务彼此之间通信的网络

```plantuml
@startuml
!include  https://plantuml.s3.cn-north-1.jdcloud-oss.com/C4_Container.puml

Boundary(管理网络, 管理网络, vlan-a) {
    System(git, git)
    System(dockerRepo, docker  repo)
    System(k8smaster, k8s master)
    System(etcd, etcd)
    System(elk, elk)
    System(jenkins, jenkins)
    System(prometheus, prometheus)
    System(容器云运维平台, 容器云运维平台)
}
@enduml
```

该网络的主要流量构成为

* k8s集群与api server之间的通信
* etcd与api server之间的通信
* k8s集群与git、docker仓库等通信
* 监控、日志系统与k8s集群之间的通信
* 企业容器云运维和运营人员通过企业内网与容器云运维(营)平台间的通信

该网络**推荐**使用一个独立的vlan号从而避免受到其它网络的二层数据干扰，该网络中的若干子网如下

```plantuml
@startuml
!include  https://plantuml.s3.cn-north-1.jdcloud-oss.com/C4_Container.puml
Boundary(管理网, 管理网, 100.64.0.0/16) {
  System(管理网路由器,管理网路由器)
  Boundary(云管理系统, 云管理系统网段, 100.64.0.0/18)
  Boundary(k8s系统网段, k8s管理和控制系统网段, 100.64.64.0/18)
  Boundary(企业内网隔离子网, 企业内网应用映射区, 100.64.128.0/18)
  Boundary(预留地址, 预留地址, 100.64.192.0/18)
  Boundary(企业网, 企业网, 各种内部系统)
}

管理网路由器 -d-> 云管理系统
管理网路由器 -d-> k8s系统网段
管理网路由器 -d-> 企业内网隔离子网
管理网路由器 -u-> 企业网
@enduml
```

首先管理网将使用100.64.0.0/10这个运营商级保留地址的16位掩码，计划领走60000+个ip地址，
并假定会有3个可能的机房(3个可用区)来消耗这些地址。

这些地址的用途也主要分为3类

* 部署云的管理系统以及比如docker repo，git之类的系统使用的云管理系统网段
* 部署k8s集群，并主要支持管理和控制系统之间通信的k8s管理和控制系统网段
* 将云管理系统与企业内部打通使用的缓冲区，企业内网应用映射区

因此，整个地址池再划分为4个子池，3个分配给以上的内容，1个留作备用

## 云管理系统

云管理系统网段的用途是部署云管平台的系统应用和界面，包含运维管理员使用的控制台和租户使用的控制台，该子网计划分配16382个可用ip，
可直接部署16000+个云管理用服务，向下以20位掩码按照机房切分。可以且分为4段，前3段为3个机房地址池，第4段保留。
这样的好处是，每一个机房内部的系统请求在自己机房就消化了，只有跨子网的请求才需要走专线去另一个机房，同时二层广播也不会出机房边界
(3层的跨子网通信默认走网关，不会进行arp广播)，避免专线承担广播流量。

```plantuml
@startuml
!include  https://plantuml.s3.cn-north-1.jdcloud-oss.com/C4_Container.puml
Boundary(管理网, 管理系统, 100.64.0.0/18) {
  Boundary(云管理系统1, 100.64.0.0/20, AZ-1)
  Boundary(云管理系统2, 100.64.16.0/20, AZ-2)
  Boundary(云管理系统3, 100.64.32.0/20, AZ-3)
  Boundary(云管理系统4, 保留段, 100.64.48.0/20)
}
@enduml
```

## k8s管理和控制系统网段

k8s系统网络部署有k8s的工作组件，包含master、worker等，同样有16382个ip，同样用20位掩码划分子网段，前3段作为机房内使用，第4段保留。

**不推荐**k8s管理和控制系统网段划子网，理由是master和worker之间有大量的api server的调用和状态上报，划了子网后流量各种都要经过网关没有意义。

同时，为了保证跨机房后k8s集群节点之间underlay网络能够进行二层广播，可能需要在多机房之间实现大二层网络。

```plantuml
@startuml
!include  https://plantuml.s3.cn-north-1.jdcloud-oss.com/C4_Container.puml
Boundary(k8s, k8s管理和控制系统网段, 100.64.64.0/18) {
  Boundary(k8s系统网段1, 100.64.64.0/20, AZ-1)
  Boundary(k8s系统网段2, 100.64.80.0/20, AZ-2)
  Boundary(k8s系统网段3, 100.64.96.0/20, AZ-3)
  Boundary(k8s系统网段4, 保留段, 100.64.111.0/20)
}
@enduml
```

## 企业内网应用映射区

在一个机房内，云管理系统和k8s都可能要求访问企业内部的系统(比如发出告警)或者被企业内部的人员/系统访问
(比如运维通过企业内网登录运维控制台)。
面对这种需求，需要一个中间区域来代理业务网的内部应用。理由是企业内部的系统实在太多，每一个都在管理网直接用企业内部ip访问

* 企业内部ip可能和集群内的若干网络重合，造成无法访问
* 路由设置和nat设置过于复杂

因此管理网访问企业内部应用需要有1个或者几个稳定的访问入口。

和其他网络一样，按20位掩码切分。

```plantuml
@startuml
!include  https://plantuml.s3.cn-north-1.jdcloud-oss.com/C4_Container.puml
Boundary(企业内网应用映射区, 企业内网应用映射区, 100.64.128.0/18) {
  Boundary(企业内网应用映射区1, 100.64.128.0/20, AZ-1)
  Boundary(企业内网应用映射区2, 100.64.144.0/20, AZ-2)
  Boundary(企业内网应用映射区3, 100.64.160.0/20, AZ-3)
  Boundary(企业内网应用映射区4, 保留段, 100.64.176.0/20)
}
@enduml
```

下面给出一个云管平台连接企业内部单点登录用token换用户信息的例子:

```plantuml
@startuml
!include  https://plantuml.s3.cn-north-1.jdcloud-oss.com/C4_Container.puml
Boundary(管理网, 管理网, 100.64.0.0/16) {
  System(管理网路由器,管理网路由器)
  Boundary(云管理系统, 云管理系统网段, 100.64.0.0/18) {
    System(云管控制台, 云管控制台, 100.64.0.2)
  }
  Boundary(企业内网隔离子网, 企业内网应用映射区, 100.64.128.0/18) {
    Container(单点登录映射地址, 单点登录映射地址, 100.64.128.2)
  }
  Boundary(企业网, 企业网, 各种内部系统) {
    System(单点登录, 单点登录, 10.0.0.2)
    Container(负载均衡网卡, 负载均衡网卡, 10.0.0.3)
  }
  
  云管控制台 -r-> 管理网路由器: 路由查找
  管理网路由器 -d-> 单点登录映射地址: 包转发
  单点登录映射地址 <-l-> 负载均衡网卡
    负载均衡网卡 <-->单点登录
}

@enduml
```

这是一个非常清晰的网络，企业内网应用有一个较为统一的负载均衡入口，被称为出向应用网关，该网关在映射区和企业网均有ip地址，使用反向代理技术让云管平台通过访问100.64.128.2获得访问单点登录系统的功能。
类似的做法可用于管理网内部的应用向企业网开放，建设多网卡LB作为应用代理是一种简单易懂且使用的方案。

# 容器流量网络

容器流量网络的作用是给容器云的pod提供东西向和南北向网络通信，也就是单独给租户用的网络。这个网络理论上能够从互联网访问进来，并能够访问互联网。

流量网计划从100.65.0.0/16领走60000+个地址。原则上来说，k8s容器流量网络只有k8s集群的节点。

```plantuml
@startuml
!include  https://plantuml.s3.cn-north-1.jdcloud-oss.com/C4_Container.puml

Boundary(容器流量网络, 容器流量网络, vlan-b) {
    System(k8smaster, k8s master)
    System(k8swoker, k8s worker)
    System(k8ingress, k8s ingress)
}
@enduml
```

该网络的主要流量构成为

* pod和集群内外部的数据和调用流量

该网络**推荐**使用一个独立的vlan号从而避免受到其它网络的二层数据干扰。

由于网络内主要是k8s的节点，因此网络内部不设子网，只是按照20位地址进行划分


```plantuml
@startuml
!include  https://plantuml.s3.cn-north-1.jdcloud-oss.com/C4_Container.puml
Boundary(容器流量网, 容器流量网, 100.65.0.0/16) {
  Boundary(容器流量网1, 100.65.0.0/20, AZ-1)
  Boundary(容器流量网2, 100.65.16.0/20, AZ-2)
  Boundary(容器流量网3, 100.65.32.0/20, AZ-3)
  Boundary(容器流量网4, 保留段, 其它)
}
@enduml
```

容器网络的一个主要作用是支持外部和内部的南北向流量，由于两个子网的南北向流量都要经过默认网关(上图的容器网路由器)，
因此南北向流量的DNAT要配置在容器网路由器上，出网的SNAT则按照路由的默认路径走向整个机房的出口。拓扑图示例如下

```plantuml
@startuml
!include  https://plantuml.s3.cn-north-1.jdcloud-oss.com/C4_Container.puml

Person(用户, 用户)
Boundary(机房网络, 机房网络) {
  System(入口ip, 入口ip)
  System(出网ip, 出网ip)
  System(安全防护设备,安全防护设备)
  System(前端负载均衡, 前端负载均衡, 10.0.x.100)
  Container(10.0.x.2, 10.0.x.2)
  Container(10.0.x.3, 10.0.x.3)
  Container(10.0.x.4, 10.0.x.4)
  
  Container(10.0.x.200, 10.0.x.200)
  System(容器网路由器,容器网路由器)
  Boundary(master子网, master 子网, 100.64.16.0/24)
  Boundary(worker子网, worker 子网, 100.64.17.0/24) {
    Container(100.64.17.2, 100.64.17.2, ingress)
    Container(100.64.17.3, 100.64.17.3, ingress)
    Container(100.64.17.4, 100.64.17.4, ingress)
  }
  用户 <-d->入口ip
  入口ip <-r-> 安全防护设备
  10.0.x.200<-r->出网ip
  安全防护设备 <-r-> 前端负载均衡
  前端负载均衡 <-d-> 10.0.x.2
  前端负载均衡 <-d-> 10.0.x.3
  前端负载均衡 <-d-> 10.0.x.4
  10.0.x.2 <-d-> 容器网路由器: dnat -> 100.64.17.2
  10.0.x.3 <-d-> 容器网路由器: dnat -> 100.64.17.3
  10.0.x.4 <-d-> 容器网路由器: dnat -> 100.64.17.4
  10.0.x.200 <-d-> 容器网路由器
  容器网路由器<-d-> 100.64.17.2
  容器网路由器<-d-> 100.64.17.3
  容器网路由器<-d-> 100.64.17.4
  容器网路由器<-d->master子网
}
@enduml
```

按照上图的样例, 在容器路网路由器配置DNAT规则到3台ingress

* dnat: src == 10.0.x.100 && dst == 10.0.x.2: 10.0.x.2 -> 100.64.17.2
* dnat: src == 10.0.x.100 && dst == 10.0.x.3: 10.0.x.2 -> 100.64.17.3
* dnat: src == 10.0.x.100 && dst == 10.0.x.4: 10.0.x.2 -> 100.64.17.4

同时配置SNAT规则(按照路由设置，3台ingress的出网流量应当经过容器网路由器)，因为负载均衡的转发，使得ingress看到的访问ip是10.0.x.100

* snat: src == 100.64.17.2 && dst == 10.0.x.100: 100.64.17.2 -> 10.0.x.2
* snat: src == 100.64.17.3 && dst == 10.0.x.100: 100.64.17.3 -> 10.0.x.3
* snat: src == 100.64.17.4 && dst == 10.0.x.100: 100.64.17.4 -> 10.0.x.4

为了100.64网段的机器能够出互联网，配置整体SNAT规则

* snat: src == 100.64.16.0/24 && dst !=100.64.0.0/10 -> 10.0.x.200
* snat: src == 100.64.17.0/24 && dst !=100.64.0.0/10 -> 10.0.x.200

以上规则将100.64之间的网络转发屏蔽，以免worker子网与master子网之间的通信被snat干扰
(未来还有容器网络和管理网络以及存储网络通信的需求)

**警告**: 整体出网SNAT规则的顺序要低于ingress向前段反向代理进行snat的规则；

# 存储流量网络

该网络用于宿主机连接后台块存储设备、文件存储设备以及对象存储设备、数据库、缓存等中间件。
该网络的存在有利于在访问流量峰值到达时，降低因后台数据访问而造成的容器网络数据拥塞。

该网络的主要流量构成为

* 物理机对远程块存储设备的数据访问流量
* pod对外部对象存储，文件存储等存储设施的直接访问流量
* pod对外部数据库，缓存等中间件的访问流量

该网络**推荐**使用一个独立的vlan号从而避免受到其它网络的二层数据干扰

## 服务器网卡规划

由网络规划可以导出服务器需要3块网卡，1个千兆(管理流量)，2个万兆(容器流量网络和存储流量网络)，实际采购过程中按预期的调用峰值和历史观测值执行。
此外，网卡之间是否进行bond(mode=1(active-backup))、是否和交换机之间执行双上联从而通过交换机堆叠或链路聚合等达成硬件高可用或高性能，
视**财力**和**财力**(确信)而为。 在预算紧张的情况下，网卡的合并规则是存储流量网与容器流量网合并，但**绝对**不推荐3合1模式